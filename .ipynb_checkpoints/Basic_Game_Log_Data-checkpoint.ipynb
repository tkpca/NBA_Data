{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import winsound\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Used to make a beef noise to indicate the script is complete. This will only work in Windows\"\"\"\n",
    "def beep_sound():\n",
    "    duration = 2000  # milliseconds\n",
    "    freq = 1500  # Hz\n",
    "    winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Function is used to pull the request data'''\n",
    "async def get_json(client,url,headers,params):\n",
    "    async with client.get(url,params=params,headers=headers) as response:\n",
    "        try:\n",
    "            assert response.status==200\n",
    "            ret=await response.json()\n",
    "            return ret\n",
    "        except AssertionError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " async def response_basic_summ(wait_base,client,headers,game,params):\n",
    "    wait_t=random.uniform(0,wait_base)\n",
    "    await asyncio.sleep(wait_t)\n",
    "    params['GameID']=game\n",
    "    url_summ='https://stats.nba.com/stats/boxscoresummaryv2'\n",
    "    response_summ= await get_json(client,url_summ,headers,params)\n",
    "    return response_summ\n",
    "\n",
    "'''The main courtine. This will be invoked to pull a list of all the JSON results from stats.nba.com'''\n",
    "async def main(game_list_key,year_param,season_param,wait_base):\n",
    "    wait_base=wait_base\n",
    "    start_time = time.time()\n",
    "    \n",
    "    '''Need to pass headers and the game ID for box score summary data'''\n",
    "    headers = {\n",
    "    'Host': 'stats.nba.com',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:71.0) Gecko/20100101 Firefox/71.0',\n",
    "    'Accept': 'application/json, text/plain, */*',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Referer': 'https://stats.nba.com/',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Connection': 'keep-alive',\n",
    "        }\n",
    "\n",
    "    payload={}\n",
    "    payload['GameID']='0021400340'\n",
    "    \n",
    "    conn= aiohttp.TCPConnector(limit=50)\n",
    "    \n",
    "    async with aiohttp.ClientSession(connector=conn) as client: #create the client sesson object that persists across requests\n",
    "        '''create task is used to start the task to pull all the asynch requests'''\n",
    "        summ_box_data=[asyncio.create_task(response_basic_summ(wait_base,client,headers,game,payload)) for game in game_list_key]\n",
    "            \n",
    "        '''The await...gather ensures all of the queries are complete before the function returns the list of JSONs back to the main program'''    \n",
    "        results = await asyncio.gather(*summ_box_data, return_exceptions=True)\n",
    "        print(\"it took --- %s seconds ---\" % (time.time() - start_time),'to go through:'+str(len(game_list_key))+' games')\n",
    "        return(results)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function returns a list of GameIDs for the selected season'''\n",
    "def game_list_gen(year_to_pull):\n",
    "    game_list=['002'+str(year_to_pull)[2:4] + str(i).zfill(5) for i in range(1,1231)] #002 is the prefix, plus last two digits of the year+games 1-1230 padded to 5 digits\n",
    "    return game_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Because the JSONs have nested lists we need to flatten them to create the dataframes'''\n",
    "def flat_list(list_to_flatten):\n",
    "    flat_list = [item for sublist in list_to_flatten for item in sublist]\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''build the list that flattens each of the JSON results from each table\n",
    "First initialize all the dictionaries\n",
    "Then take the results for the year and convert to a dictionary with the GameID as the key\n",
    "Loop through each game and build each of the respective dictionaries\n",
    "'''\n",
    "\n",
    "'''Create the column headers for the tables + mark the first column as the GameID (GID)'''\n",
    "\n",
    "datatables=['GameSummary','OtherStats', 'Officials', 'InactivePlayers', 'GameInfo', 'LineScore', 'LastMeeting', 'SeasonSeries'] #a list of the tables returned from the summary query\n",
    "\n",
    "def build_datatable(results):\n",
    "    \n",
    "    #clear dataframes for garbage collection\n",
    "    try:\n",
    "        del df_GameSummary \n",
    "        del df_OtherStats \n",
    "        del df_Officials \n",
    "        del df_InactivePlayers \n",
    "        del df_GameInfo \n",
    "        del df_LineScore \n",
    "        del df_LastMeeting \n",
    "        del df_SeasonSeries \n",
    "        del df_InactivePlayers \n",
    "        del df_GameInfo \n",
    "        del df_LineScore \n",
    "        del df_LastMeeting \n",
    "        del df_SeasonSeries \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    GameSummary=[]\n",
    "    OtherStats=[]\n",
    "    Officials=[]\n",
    "    InactivePlayers=[]\n",
    "    GameInfo=[]\n",
    "    LineScore=[]\n",
    "    LastMeeting=[]\n",
    "    SeasonSeries=[] \n",
    "    \n",
    "    #Build the column headers for the datatable\n",
    "    GameSummary_col=['GID']+(results[0]['resultSets'][0]['headers'])\n",
    "    OtherStats_col=['GID']+(results[0]['resultSets'][1]['headers'])\n",
    "    Officials_col=['GID']+(results[0]['resultSets'][2]['headers'])\n",
    "    InactivePlayers_col=['GID']+(results[0]['resultSets'][3]['headers'])\n",
    "    GameInfo_col=['GID']+(results[0]['resultSets'][4]['headers'])\n",
    "    LineScore_col=['GID']+(results[0]['resultSets'][5]['headers'])\n",
    "    LastMeeting_col=['GID']+(results[0]['resultSets'][6]['headers'])\n",
    "    SeasonSeries_col=['GID']+(results[0]['resultSets'][7]['headers'])\n",
    "    \n",
    "    r={}\n",
    "    error_cnt=0 #track the number of exceptions\n",
    "    \n",
    "    #Split the result sets. Since some data may be corrupted a dict comprehension won't work\n",
    "    for i in range(0, len(results)):\n",
    "        try:\n",
    "            r[(results[i]['parameters']['GameID'])] = results[i]['resultSets']\n",
    "        except (RuntimeError, TypeError, NameError) as e:\n",
    "            error_cnt+=1\n",
    "            continue\n",
    "\n",
    "    for k,v in r.items():\n",
    "        GameSummary.append([[k]+ row_d for row_d in r[k][0]['rowSet'] if row_d is not None])\n",
    "        OtherStats.append([[k]+ row_d for row_d in r[k][1]['rowSet'] if row_d is not None])\n",
    "        Officials.append([[k]+ row_d for row_d in r[k][2]['rowSet'] if row_d is not None])\n",
    "        InactivePlayers.append([[k]+ row_d for row_d in r[k][3]['rowSet'] if row_d is not None])\n",
    "        GameInfo.append([[k]+ row_d for row_d in r[k][4]['rowSet'] if row_d is not None])\n",
    "        LineScore.append([[k]+ row_d for row_d in r[k][5]['rowSet'] if row_d is not None])\n",
    "        LastMeeting.append([[k]+ row_d for row_d in r[k][6]['rowSet'] if row_d is not None])\n",
    "        SeasonSeries.append([[k]+ row_d for row_d in r[k][7]['rowSet'] if row_d is not None])\n",
    "\n",
    "    #Need to flatten the results in order to build the datatables\n",
    "    GameSummary=flat_list(GameSummary)\n",
    "    OtherStats=flat_list(OtherStats)\n",
    "    Officials=flat_list(Officials)\n",
    "    InactivePlayers=flat_list(InactivePlayers)\n",
    "    GameInfo=flat_list(GameInfo)\n",
    "    LineScore=flat_list(LineScore)\n",
    "    LastMeeting=flat_list(LastMeeting)\n",
    "    SeasonSeries=flat_list(SeasonSeries)\n",
    "    \n",
    "    #build the 8 datatables and label the columns\n",
    "    df_GameSummary = pd.DataFrame(GameSummary, columns=GameSummary_col)\n",
    "    df_OtherStats = pd.DataFrame(OtherStats, columns=OtherStats_col)\n",
    "    df_Officials = pd.DataFrame(Officials, columns=Officials_col)\n",
    "    df_InactivePlayers = pd.DataFrame(InactivePlayers, columns=InactivePlayers_col)\n",
    "    df_GameInfo = pd.DataFrame(GameInfo, columns=GameInfo_col)\n",
    "    df_LineScore = pd.DataFrame(LineScore, columns=LineScore_col)\n",
    "    df_LastMeeting = pd.DataFrame(LastMeeting, columns=LastMeeting_col)\n",
    "    df_SeasonSeries = pd.DataFrame(SeasonSeries, columns=SeasonSeries_col)\n",
    "    \n",
    "    #keep a list of the dataframes for reference\n",
    "    df_list=[]\n",
    "    df_list=df_GameSummary, df_OtherStats, df_Officials, df_InactivePlayers, df_GameInfo, df_LineScore, df_LastMeeting, df_SeasonSeries\n",
    "    \n",
    "    #return each of the dataframes\n",
    "    return df_GameSummary, df_OtherStats, df_Officials, df_InactivePlayers, df_GameInfo, df_LineScore, df_LastMeeting, df_SeasonSeries,df_list,error_cnt\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Pick the first season to scrape: 1980\n",
      "Pick the last season to scrape: 2019\n",
      "~how many seconds should the requests take in total? 1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following years were selected: [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]\n",
      "it took --- 1201.255652666092 seconds --- to go through:1230 games\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'df_LineScore1980-1981.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-7f00838ed876>\u001b[0m in \u001b[0;36masync-def-wrapper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mdf_LastMeeting\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SEASON'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myear_param\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mdf_LastMeeting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'df_LastMeeting{year_param}.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mdf_SeasonSeries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SEASON'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myear_param\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3226\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3227\u001b[0m         )\n\u001b[1;32m-> 3228\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3230\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    181\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m                 \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m             )\n\u001b[0;32m    185\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'df_LineScore1980-1981.csv'"
     ]
    }
   ],
   "source": [
    "'''This code runs the main loop\n",
    "First it takes user input to determine how many seasons of data to scrape.\n",
    "Second it converts those into a list used for the loop.\n",
    "Finally it invokes the main function to run the aynchio loop'''\n",
    "\n",
    "#first_year=int(input('What is the first year of the season to pull:'))\n",
    "#last_year=int(input('What is the last year of the season to pull:'))\n",
    "first_year=int(input('Pick the first season to scrape:'))\n",
    "last_year=int(input('Pick the last season to scrape:'))\n",
    "wait_base=int(input('~how many seconds should the requests take in total?'))\n",
    "years_to_pull=[x for x in range(first_year,last_year+1)] #create a list with the years to loop through\n",
    "\n",
    "#print the seasons that will be pulled\n",
    "print(f'The following years were selected: {years_to_pull}')\n",
    "\n",
    "#loop through each of the seasons\n",
    "for year_to_pull in years_to_pull:\n",
    "    year_param=((str(year_to_pull)+'-'+str((int(year_to_pull)+1)))) \n",
    "    season_param=((str(year_to_pull)+'-'+str((int(year_to_pull)+1))[2:4])) #season parameter for the query\n",
    "    \n",
    "    game_list_key=game_list_gen(year_to_pull) #call a function to generate the GameIDs for selected season\n",
    "    start_time = time.time()\n",
    "    results= await main(game_list_key[:],year_to_pull,season_param,wait_base) #this would be asyncio.run(main(client)) in plain Python(https://bit.ly/36MtBDI)\n",
    "    \n",
    "    #call the function to build and return each of the datatables\n",
    "    df_GameSummary, df_OtherStats, df_Officials, df_InactivePlayers, df_GameInfo, df_LineScore, df_LastMeeting, df_SeasonSeries,df_list,error_cnt=build_datatable(results)\n",
    "    \n",
    "    #add the season parameter to the 8 datatables before they are saved for sorting later\n",
    "    df_GameSummary['SEASON']=year_param\n",
    "    df_GameSummary.to_csv(f'df_GameSummary{year_param}.csv')\n",
    "    \n",
    "    df_OtherStats['SEASON']=year_param\n",
    "    df_OtherStats.to_csv(f'df_OtherStats{year_param}.csv')\n",
    "    \n",
    "    df_Officials['SEASON']=year_param\n",
    "    df_Officials.to_csv(f'df_Officials{year_param}.csv')\n",
    "        \n",
    "    df_InactivePlayers['SEASON']=year_param\n",
    "    df_InactivePlayers.to_csv(f'df_InactivePlayers{year_param}.csv')\n",
    "        \n",
    "    df_GameInfo['SEASON']=year_param\n",
    "    df_GameInfo.to_csv(f'df_GameInfo{year_param}.csv')\n",
    "    \n",
    "    df_LineScore['SEASON']=year_param\n",
    "    df_LineScore.to_csv(f'df_LineScore{year_param}.csv')\n",
    "    \n",
    "    df_LastMeeting['SEASON']=year_param\n",
    "    df_LastMeeting.to_csv(f'df_LastMeeting{year_param}.csv')\n",
    "    \n",
    "    df_SeasonSeries['SEASON']=year_param\n",
    "    df_SeasonSeries.to_csv(f'df_SeasonSeries{year_param}.csv')\n",
    "    \n",
    "    beep_sound() #make the computer beep when the script is finished running\n",
    "    print(\"it took --- %s seconds ---\" % (time.time() - start_time)+'to go through everything for the ' + year_param + ' season' + ' and there were ' + 'error_cnt' + ': rows with errors')\n",
    "    time.sleep(random.uniform(0,13)) #pause season pulls to reduce the chances of being throttled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
