{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,timedelta #import the datetime module\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import winsound\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Pandas display options\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#set the subdirectory to save the tables\n",
    "savedir=os.getcwd()+'\\\\datatables\\\\gamelogs\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Used to make a beep noise to indicate the script is complete. This will only work in Windows\"\"\"\n",
    "def beep_sound():\n",
    "    duration = 2000  # milliseconds\n",
    "    freq = 1500  # Hz\n",
    "    winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''A dictionary that is used to map the visitor team ID to the abbreviation'''\n",
    "team_dict={1610612737: 'ATL',\n",
    " 1610612738: 'BOS',\n",
    " 1610612751: 'BKN',\n",
    " 1610612766: 'CHA',\n",
    " 1610612741: 'CHI',\n",
    " 1610612739: 'CLE',\n",
    " 1610612742: 'DAL',\n",
    " 1610612743: 'DEN',\n",
    " 1610612765: 'DET',\n",
    " 1610612744: 'GSW',\n",
    " 1610612745: 'HOU',\n",
    " 1610612754: 'IND',\n",
    " 1610612746: 'LAC',\n",
    " 1610612747: 'LAL',\n",
    " 1610612763: 'MEM',\n",
    " 1610612748: 'MIA',\n",
    " 1610612749: 'MIL',\n",
    " 1610612750: 'MIN',\n",
    " 1610612740: 'NOP',\n",
    " 1610612752: 'NYK',\n",
    " 1610612760: 'OKC',\n",
    " 1610612753: 'ORL',\n",
    " 1610612755: 'PHI',\n",
    " 1610612756: 'PHX',\n",
    " 1610612757: 'POR',\n",
    " 1610612758: 'SAC',\n",
    " 1610612759: 'SAS',\n",
    " 1610612761: 'TOR',\n",
    " 1610612762: 'UTA',\n",
    " 1610612764: 'WAS'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the season is in progress filter out any games that have not taken place from the pull\n",
    "def current_year_filter(year_to_pull,game_list):\n",
    "    df_data=pd.read_csv(f'{savedir}{year_to_pull}_schedule.csv',names=['game_id', 'game_date'],dtype={'game_id': object})\n",
    "    df_data['game_date'] =  pd.to_datetime(df_data['game_date'], format='%Y-%m-%d')\n",
    "    df_data=df_data[df_data.game_date < (datetime.today() +timedelta(days=-1))]\n",
    "    return df_data.game_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function sets the upper bound on how many queries to send per year depending on the season\n",
    "def total_games(season):\n",
    "    if season == 1998:\n",
    "        total_g=725\n",
    "    elif season ==2011:\n",
    "        total_g=1025\n",
    "    elif season <=1987:\n",
    "        total_g=943\n",
    "    elif season <=1994:\n",
    "        total_g=1107\n",
    "    elif season <=1994:\n",
    "        total_g=1189\n",
    "    else:\n",
    "        total_g=1230\n",
    "    return total_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_basic_box_df(basic_box):\n",
    "\n",
    "    # the data for the basic box score data results (basic_box[0]['resultSets'][0]['rowSet']) --> first list is for the games\n",
    "    '''basic_box[2]['parameters']['GameID'] get the column for the gameID '''\n",
    "    '''basic_box[0]['resultSets'][0]['rowSet'] the results for a single game '''\n",
    "\n",
    "    df_data=[]\n",
    "    errors=[] #log rows with errors\n",
    "    count=0\n",
    "    \n",
    "    for i in basic_box:\n",
    "        try: #this only works if there are results\n",
    "            for j in range(len(i['resultSets'][0]['rowSet'])):\n",
    "                df_data.append(i['resultSets'][0]['rowSet'][j]) #note last index is the player\n",
    "                count+=1\n",
    "        except TypeError:\n",
    "            errors.append(count)\n",
    "            count+=1\n",
    "    print(f'there were: {len(errors)} errors in the basic box score data')\n",
    "    df_basic_box = pd.DataFrame(df_data,columns=basic_box[0]['resultSets'][0]['headers'])\n",
    "    return(df_basic_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adv_box_df(adv_box):\n",
    "\n",
    "    # the data for the adv box score data results (adv_box[0]['resultSets'][0]['rowSet']) --> first list is for the games\n",
    "\n",
    "    df_data=[]\n",
    "    errors=[] #log rows with errors\n",
    "    count=0\n",
    "    \n",
    "    for i in adv_box:\n",
    "        try:\n",
    "            for j in range(len(i['resultSets'][0]['rowSet'])):\n",
    "                df_data.append(i['resultSets'][0]['rowSet'][j]) #note last index is the player\n",
    "                count+=1\n",
    "        except TypeError:\n",
    "            errors.append(count)\n",
    "            count+=1\n",
    "    print(f'there were: {len(errors)} errors in the advanced box score data')\n",
    "    df_adv_box = pd.DataFrame(df_data,columns=adv_box[0]['resultSets'][0]['headers'])\n",
    "    return(df_adv_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summ_box_df(summ_box):\n",
    "\n",
    "    # the data for the adv box score data results (adv_box[0]['resultSets'][0]['rowSet']) --> first list is for the games\n",
    "\n",
    "    df_data=[]\n",
    "    errors=[] #log rows with errors\n",
    "    count=0\n",
    "    \n",
    "    try:\n",
    "        for i in range(0,len(summ_box)):\n",
    "            df_data.append(summ_box[i]['resultSets'][0]['rowSet'][0])\n",
    "            count+=1\n",
    "    except TypeError:\n",
    "        errors.append(count)\n",
    "        count+=1\n",
    "    print(f'there were: {len(errors)} errors in the summary box score data')\n",
    "    df_summ_box = pd.DataFrame(df_data,columns=summ_box[0]['resultSets'][0]['headers'])\n",
    "    return(df_summ_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_json(client,url,headers,params=''):\n",
    "    async with client.get(url,params=params,headers=headers) as response:\n",
    "        try:\n",
    "            assert response.status==200\n",
    "            ret=await response.json()\n",
    "            return ret\n",
    "        except AssertionError:\n",
    "            pass\n",
    "\n",
    "async def response_basic(wait_base,client,headers,payload_basic,game):\n",
    "    wait_t=random.uniform(0,wait_base)\n",
    "    await asyncio.sleep(wait_t)\n",
    "    payload_basic['GameID']=game\n",
    "    url_basic='https://stats.nba.com/stats/boxscoretraditionalv2'\n",
    "    response_basic= await get_json(client,url_basic,headers,payload_basic)\n",
    "    return response_basic\n",
    "    \n",
    "    \n",
    "async def response_basic_summ(wait_base,client,headers,game):\n",
    "    wait_t=random.uniform(0,wait_base)\n",
    "    await asyncio.sleep(wait_t)\n",
    "    url_summ='https://stats.nba.com/stats/boxscoresummaryv2?GameID=' +game \n",
    "    response_summ= await get_json(client,url_summ,headers)\n",
    "    return response_summ\n",
    "\n",
    "async def response_adv(wait_base,client,headers,payload_basic,game):\n",
    "    wait_t=random.uniform(0,wait_base)\n",
    "    await asyncio.sleep(wait_t)\n",
    "    payload_basic['GameID']=game\n",
    "    url_adv='https://stats.nba.com/stats/boxscoreadvancedv2' \n",
    "    response_adv= await get_json(client,url_adv,headers,payload_basic)\n",
    "    return response_adv\n",
    "\n",
    "\n",
    "async def main(game_list_key,year_param,season_param,wait_base):\n",
    "    wait_base=wait_base\n",
    "    start_time = time.time()\n",
    "    #the headers to pass in the query\n",
    "    headers = {\n",
    "    'Host': 'stats.nba.com',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:71.0) Gecko/20100101 Firefox/71.0',\n",
    "    'Accept': 'application/json, text/plain, */*',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Referer': 'https://stats.nba.com/',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Connection': 'keep-alive',\n",
    "        }\n",
    "\n",
    "    '''the query parameters for the basic and advanced stats. The game ID needs to be revised in each query. The other parameters appear to be work if they remain static\n",
    "    the season param is required for queries prior to 1999-20\n",
    "    '''\n",
    "    payload_basic={'EndPeriod': '10',\n",
    "    'EndRange': '28800',\n",
    "    'GameID': '0021400340',\n",
    "    'RangeType': '0',\n",
    "    'Season': season_param,\n",
    "    'SeasonType': 'Regular Season',\n",
    "    'StartPeriod': '1',\n",
    "    'StartRange': '0'}    \n",
    "    payload_basic['Season']=season_param\n",
    "    \n",
    "    conn= aiohttp.TCPConnector(limit=100)\n",
    "    \n",
    "    async with aiohttp.ClientSession(connector=conn) as client: #create the client sesson object that persists across requests\n",
    "        '''Each of these calls the corotines to pull the basic box score stats, advanced score stats, and summary data that will be used to create the dataframe for the season'''\n",
    "        basic_box_data=[asyncio.create_task(response_basic(wait_base,client,headers,payload_basic,game)) for game in game_list_key]\n",
    "        summ_box_data=[asyncio.create_task(response_basic_summ(wait_base,client,headers,game)) for game in game_list_key]\n",
    "        adv_box_data=[asyncio.create_task(response_adv(wait_base,client,headers,payload_basic,game)) for game in game_list_key]\n",
    "            \n",
    "        '''The await...gather ensures all of the queries are complete before the function returns the list of JSONs back to the main program'''    \n",
    "        basic_box = await asyncio.gather(*basic_box_data, return_exceptions=True)\n",
    "        summ_box = await asyncio.gather(*summ_box_data, return_exceptions=True)\n",
    "        adv_box = await asyncio.gather(*adv_box_data, return_exceptions=True)\n",
    "        print(\"it took --- %s seconds ---\" % (time.time() - start_time),'to go through:'+str(len(game_list_key))+' games')\n",
    "        return(basic_box,summ_box,adv_box)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function builds the final dataframe and saves for the entire season\"\"\"\n",
    "def build_df(basic_box,adv_box,summ_box,year_param):\n",
    "    #convert the JSON into Dataframes\n",
    "    df_basic_box=create_basic_box_df(basic_box)\n",
    "    df_adv_box=create_adv_box_df(adv_box)\n",
    "    df_summ_box=create_summ_box_df(summ_box)\n",
    "    check=0 #this needs to change to 1 to flag some of the additional transformations. It prevents merge errors when there is no advanced or basic box score data\n",
    "    #merge the dataframes and save to hdf\n",
    "    \n",
    "    if df_adv_box.empty == False:\n",
    "        df_adv_box.drop(columns=['E_USG_PCT','E_PACE','E_OFF_RATING','E_DEF_RATING','E_NET_RATING'],inplace=True)\n",
    "        df_total_year= df_basic_box.merge(df_adv_box, left_on=['GAME_ID','PLAYER_ID'], right_on=['GAME_ID','PLAYER_ID'],suffixes=('', '_delete'),how='left') #merge basic and advanced stats using the player as the key\n",
    "        check=1 #flag for transformation code\n",
    "    else:\n",
    "        df_total_year= df_basic_box #if the join fails because there are no advanced stats\n",
    "    \n",
    "    if df_summ_box.empty == False:\n",
    "        df_total_year=df_total_year.merge(df_summ_box, left_on='GAME_ID', right_on='GAME_ID',suffixes=('', '_delete'),how='left') #merge basic and advanced stats with box_score summary data using the player as the key\n",
    "        check=1 #flag for transformation code\n",
    "    \n",
    "    \n",
    "    if check == 1:\n",
    "        df_total_year=df_total_year.loc[:,~df_total_year.columns.str.endswith('_delete')] #remove the duplicated columns\n",
    "        \n",
    "    df_total_year['SEASON']=year_param #add the season\n",
    "    df_total_year['HM_AW']=np.where(df_total_year.TEAM_ID==df_total_year.HOME_TEAM_ID,'H','A') #mark as home or away  \n",
    "    \n",
    "    df_total_year['OPP']=np.where(df_total_year.TEAM_ID==df_total_year.HOME_TEAM_ID,df_total_year.VISITOR_TEAM_ID,df_total_year.HOME_TEAM_ID) #mark as home or away\n",
    "    df_total_year['OPP']=df_total_year['OPP'].map(team_dict)  #get the abb for the visiting team\n",
    "    \n",
    "    \n",
    "    #Create a pivot table that tracks which team won or lost as a boolean value then merge/join into the original table so there is a filter on if a player won or lost a specific game\n",
    "    df_win_lose=(df_total_year.groupby(['GAME_ID','HM_AW'])['PTS'].sum().reset_index()).pivot(index='GAME_ID',columns='HM_AW',values='PTS')\n",
    "    df_win_lose['WINNER']=np.where(df_win_lose.H>df_win_lose.A,'H','A') #mark home or away as winner\n",
    "    df_total_year= df_total_year.merge(df_win_lose, left_on='GAME_ID', right_on='GAME_ID',suffixes=('', '_delete'))\n",
    "    df_total_year['PLAYER_WIN_OR_LOSE']=np.where(df_total_year.WINNER==df_total_year.HM_AW,1,0) #mark home or away as winner\n",
    "\n",
    "    #Flag unncessary columns and delete them.\n",
    "    #For some of the advanced stats there is a column with \"e_\" as a prefix.\n",
    "    #So if there is \"DEF_RATING\" and \"E_DEF_RATING\" NBA uses the first one so we will drop those columns\n",
    "    int_list= ['PLAYER_ID','FGM', 'FGA', 'FG3M','FG3A', 'FTM', 'FTA', 'OREB', 'DREB', 'REB', 'AST','STL', 'BLK', 'TO', 'PF', 'PTS', 'PLUS_MINUS'] #list of columns to convert to INT\n",
    "    df_total_year[int_list]=df_total_year[int_list].apply(pd.to_numeric,errors='coerce')    \n",
    "    \n",
    "    drop_col=['GAME_SEQUENCE', 'GAME_STATUS_ID', 'GAME_STATUS_TEXT',\n",
    "           'GAMECODE', 'LIVE_PERIOD',\n",
    "           'LIVE_PC_TIME', 'NATL_TV_BROADCASTER_ABBREVIATION',\n",
    "           'LIVE_PERIOD_TIME_BCAST', 'WH_STATUS','HOME_TEAM_ID','VISITOR_TEAM_ID','TEAM_CITY','A','H','FG_PCT','FG3_PCT','FT_PCT']\n",
    "    \n",
    "    df_total_year.drop(columns=drop_col,inplace=True)\n",
    "    \n",
    "    return df_total_year\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_year=int(input('What is the first year of the season to pull:'))\n",
    "#last_year=int(input('What is the last year of the season to pull:'))\n",
    "first_year=int(input('Pick the first season to scrape:'))\n",
    "last_year=int(input('Pick the last season to scrape:'))\n",
    "wait_base=int(input('~how many seconds should the requests take in total?'))\n",
    "years_to_pull=[x for x in range(first_year,last_year+1)] #create a list with the years to loop through\n",
    "\n",
    "print(f'The following years were selected: {years_to_pull}')\n",
    "\n",
    "for year_to_pull in years_to_pull:\n",
    "    year_param=((str(year_to_pull)+'-'+str((int(year_to_pull)+1))))\n",
    "    season_param=((str(year_to_pull)+'-'+str((int(year_to_pull)+1))[2:4])) #season parameter for the query\n",
    "    game_list_key =[]\n",
    "    game_range=total_games(year_to_pull)\n",
    "    game_list=['002'+str(year_to_pull)[2:4] + str(i).zfill(5) for i in range(1,game_range+1)] #002 is the prefix, plus last two digits of the year+games 1-1230 padded to 5 digits\n",
    "    #call a function to prevent querying any games that haven't taken place during the current season\n",
    "    if year_to_pull == datetime.now().year:\n",
    "        game_list=current_year_filter(year_to_pull,game_list)\n",
    "    \n",
    "    #for game_list_key in game_list[5]:\n",
    "    start_time = time.time()\n",
    "    #run the function that pulls the API results\n",
    "    basic_box,summ_box,adv_box= await main(game_list,year_to_pull,season_param,wait_base) #this would be asyncio.run(main(client)) in plain Python(https://bit.ly/36MtBDI)\n",
    "    \n",
    "    \n",
    "    df_total_year=build_df(basic_box,adv_box,summ_box,year_param)\n",
    "    df_total_year.to_parquet(f'{savedir}df_{year_param}_data.gzip',compression='gzip')\n",
    "    beep_sound() #make the computer beep when the script is finished running\n",
    "    print(\"it took --- %s seconds ---\" % (time.time() - start_time)+'to go through everything for the ' + year_param + ' season')\n",
    "    time.sleep(random.uniform(0,5)) #pause season pulls to reduce the chances of being throttled\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_parquet(savedir+'df_2019-2020_data.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_adv_box' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-ac42b6713ac5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_adv_box\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'E_USG_PCT'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'E_PACE'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'E_OFF_RATING'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'E_DEF_RATING'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'E_NET_RATING'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_adv_box' is not defined"
     ]
    }
   ],
   "source": [
    "df_adv_box.drop(columns=['E_USG_PCT','E_PACE','E_OFF_RATING','E_DEF_RATING','E_NET_RATING'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
